{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# from typing import List, Tuple, Dict, Optional\n",
    "import gym\n",
    "from gym import spaces\n",
    "from scipy import ndimage\n",
    "\n",
    "class WoodCuttingEnv(gym.Env):\n",
    "    def __init__(self, big_platform_size=(100, 100), max_platforms=5):\n",
    "        super(WoodCuttingEnv, self).__init__()\n",
    "        \n",
    "        # Initialize with the size of big wood platforms\n",
    "        self.big_platform_width, self.big_platform_height = big_platform_size\n",
    "        self.max_platforms = max_platforms\n",
    "        \n",
    "        # State: Representation of the current platform's state\n",
    "        # We'll represent it as a binary grid\n",
    "        self.grid_size = 100  # We'll use a 100x100 grid for simplicity\n",
    "        \n",
    "\n",
    "        #################################################################################\n",
    "        # Track piece types in each position (0 = empty, 1+ = piece type index + 1)\n",
    "        self.platforms = [np.zeros((self.grid_size, self.grid_size), dtype=np.int8)]\n",
    "        self.piece_types = [np.zeros((self.grid_size, self.grid_size), dtype=np.int8)]\n",
    "        #################################################################################\n",
    "\n",
    "\n",
    "        # State space: Current platform's grid state + remaining order pieces + current platform index\n",
    "        grid_space = spaces.Box(low=0, high=1, shape=(self.grid_size, self.grid_size), dtype=np.int8)\n",
    "        \n",
    "        # Max number of different piece types in an order\n",
    "        self.max_order_types = 10\n",
    "        # Order space: (width, height, quantity) for each order type\n",
    "        order_space = spaces.Box(\n",
    "            low=np.array([[1, 1, 0]] * self.max_order_types),\n",
    "            high=np.array([[self.big_platform_width, self.big_platform_height, 100]] * self.max_order_types),\n",
    "            dtype=np.int32\n",
    "        )\n",
    "        \n",
    "        # Current platform index\n",
    "        platform_index_space = spaces.Discrete(self.max_platforms + 1)  # +1 for \"no platforms left\"\n",
    "        \n",
    "        # Combine spaces\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'grid': grid_space,\n",
    "            'order': order_space,\n",
    "            'platform_index': platform_index_space\n",
    "        })\n",
    "        \n",
    "        # Action space: (x, y, piece_type, rotation)\n",
    "        # x, y: position to place the piece\n",
    "        # piece_type: which piece type from the order to use\n",
    "        # rotation: 0 or 1 (0° or 90°)\n",
    "        self.action_space = spaces.MultiDiscrete([\n",
    "            self.grid_size,  # x\n",
    "            self.grid_size,  # y\n",
    "            self.max_order_types,  # piece_type\n",
    "            2  # rotation (0 or 1)\n",
    "        ])\n",
    "        \n",
    "        # Initialize state\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self, order=None):\n",
    "        \"\"\"Reset environment with a new or provided order.\"\"\"\n",
    "\n",
    "        #################################################################################\n",
    "        # Initialize the first platform grid (0 = empty, 1 = filled)\n",
    "        self.platforms = [np.zeros((self.grid_size, self.grid_size), dtype=np.int8)]\n",
    "        self.piece_types = [np.zeros((self.grid_size, self.grid_size), dtype=np.int8)]\n",
    "        #################################################################################\n",
    "\n",
    "        # # Initialize the first platform grid (0 = empty, 1 = filled)\n",
    "        # self.platforms = [np.zeros((self.grid_size, self.grid_size), dtype=np.int8)]\n",
    "\n",
    "        self.current_platform_idx = 0\n",
    "        \n",
    "        \n",
    "        # Generate a random order if none provided\n",
    "        if order is None:\n",
    "            self.order = self._generate_random_order()\n",
    "        else:\n",
    "            self.order = order.copy()\n",
    "        \n",
    "        return self._get_observation()\n",
    "    \n",
    "    def _generate_random_order(self):\n",
    "        \"\"\"Generate a random cutting order.\"\"\"\n",
    "        num_types = np.random.randint(1, self.max_order_types + 1)\n",
    "        order = []\n",
    "        \n",
    "        for _ in range(num_types):\n",
    "            width = np.random.randint(5, min(self.big_platform_width // 2, 30) + 1)\n",
    "            height = np.random.randint(5, min(self.big_platform_height // 2, 30) + 1)\n",
    "            quantity = np.random.randint(1, 20)\n",
    "            order.append([width, height, quantity])\n",
    "        \n",
    "        # Pad the order to max_order_types\n",
    "        while len(order) < self.max_order_types:\n",
    "            order.append([0, 0, 0])\n",
    "            \n",
    "        return np.array(order)\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Return the current observation.\"\"\"\n",
    "        return {\n",
    "            'grid': self.platforms[self.current_platform_idx],\n",
    "            'order': self.order,\n",
    "            'platform_index': self.current_platform_idx\n",
    "        }\n",
    "    \n",
    "    def _is_valid_placement(self, x, y, piece_width, piece_height, platform_idx=None):\n",
    "        \"\"\"Check if a piece can be placed at (x, y) with given dimensions.\"\"\"\n",
    "        if platform_idx is None:\n",
    "            platform_idx = self.current_platform_idx\n",
    "            \n",
    "        if x + piece_width > self.grid_size or y + piece_height > self.grid_size:\n",
    "            return False\n",
    "        \n",
    "        # Check if the area is empty\n",
    "        if np.any(self.platforms[platform_idx][y:y+piece_height, x:x+piece_width] == 1):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _can_fit_anywhere(self, piece_width, piece_height, platform_idx=None):\n",
    "        \"\"\"Check if a piece can fit anywhere on the specified platform.\"\"\"\n",
    "        if platform_idx is None:\n",
    "            platform_idx = self.current_platform_idx\n",
    "            \n",
    "        for y in range(self.grid_size - piece_height + 1):\n",
    "            for x in range(self.grid_size - piece_width + 1):\n",
    "                if self._is_valid_placement(x, y, piece_width, piece_height, platform_idx):\n",
    "                    return True, (x, y)\n",
    "        return False, None\n",
    "    \n",
    "    #################################################################################\n",
    "    def _place_piece(self, x, y, piece_width, piece_height, piece_type, platform_idx=None):\n",
    "    #################################################################################\n",
    "    # def _place_piece(self, x, y, piece_width, piece_height, platform_idx=None):\n",
    "        \"\"\"Place a piece at (x, y) with given dimensions.\"\"\"\n",
    "        if platform_idx is None:\n",
    "            platform_idx = self.current_platform_idx\n",
    "            \n",
    "        self.platforms[platform_idx][y:y+piece_height, x:x+piece_width] = 1\n",
    "\n",
    "        #################################################################################\n",
    "        self.piece_types[platform_idx][y:y+piece_height, x:x+piece_width] = piece_type + 1  # +1 to avoid 0\n",
    "        #################################################################################\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take a step in the environment.\n",
    "        \n",
    "        Args:\n",
    "            action: [x, y, piece_type, rotation]\n",
    "        \n",
    "        Returns:\n",
    "            observation, reward, done, info\n",
    "        \"\"\"\n",
    "        x, y, piece_type, rotation = action\n",
    "        \n",
    "        # Check if piece_type is valid\n",
    "        if piece_type >= len(self.order) or self.order[piece_type][2] <= 0:\n",
    "            # Invalid piece type or no more pieces of this type\n",
    "            return self._get_observation(), -10, False, {'message': 'Invalid piece type'}\n",
    "        \n",
    "        # Get piece dimensions\n",
    "        width, height, quantity = self.order[piece_type]\n",
    "        \n",
    "        # Apply rotation if needed\n",
    "        if rotation == 1:\n",
    "            width, height = height, width\n",
    "        \n",
    "        # Check if placement is valid at the chosen position on the current platform\n",
    "        if not self._is_valid_placement(x, y, width, height):\n",
    "            # Try to find placement on any existing platform\n",
    "            placed = False\n",
    "            best_position = None\n",
    "            best_platform = None\n",
    "            \n",
    "            # Check all existing platforms\n",
    "            for platform_idx in range(len(self.platforms)):\n",
    "                can_fit, new_pos = self._can_fit_anywhere(width, height, platform_idx)\n",
    "                if can_fit:\n",
    "                    if best_position is None or platform_idx <= best_platform:\n",
    "                        best_position = new_pos\n",
    "                        best_platform = platform_idx\n",
    "                        placed = True\n",
    "            \n",
    "            if placed:\n",
    "                # Place at the best position found\n",
    "                x, y = best_position\n",
    "                self._place_piece(x, y, width, height, piece_type, best_platform)\n",
    "                self.order[piece_type][2] -= 1\n",
    "                # Set the current platform to where we placed the piece\n",
    "                self.current_platform_idx = best_platform\n",
    "                reward = width * height - 5  # Small penalty for repositioning\n",
    "            else:\n",
    "                # Try creating a new platform if allowed\n",
    "                if self.current_platform_idx + 1 < self.max_platforms:\n",
    "                    new_platform_idx = len(self.platforms)\n",
    "                    self.platforms.append(np.zeros((self.grid_size, self.grid_size), dtype=np.int8))\n",
    "                    self.piece_types.append(np.zeros((self.grid_size, self.grid_size), dtype=np.int8))\n",
    "                    \n",
    "                    # Place at the beginning of the new platform\n",
    "                    if self._is_valid_placement(0, 0, width, height, new_platform_idx):\n",
    "                        self._place_piece(0, 0, width, height, piece_type, new_platform_idx)\n",
    "                        self.order[piece_type][2] -= 1\n",
    "                        self.current_platform_idx = new_platform_idx\n",
    "                        reward = width * height - 50  # Reward for successful placement minus penalty for new platform\n",
    "                    else:\n",
    "                        reward = -20  # Penalty for invalid placement even on new platform\n",
    "                else:\n",
    "                    reward = -30  # No more platforms available\n",
    "                    return self._get_observation(), reward, True, {'message': 'No more platforms'}\n",
    "        else:\n",
    "            # Place the piece at the original position on current platform\n",
    "            self._place_piece(x, y, width, height, piece_type)\n",
    "            self.order[piece_type][2] -= 1\n",
    "            reward = width * height  # Reward proportional to the piece area\n",
    "        \n",
    "        # Check if all pieces have been placed\n",
    "        done = np.all(self.order[:, 2] == 0)\n",
    "        \n",
    "        # Calculate total waste (empty space) on used platforms\n",
    "        if done:\n",
    "            total_area = self.big_platform_width * self.big_platform_height * len(self.platforms)\n",
    "            filled_area = sum(np.sum(platform) for platform in self.platforms)\n",
    "            waste = total_area - filled_area\n",
    "            efficiency = filled_area / total_area\n",
    "            \n",
    "            # Add final reward based on efficiency\n",
    "            reward += efficiency * 1000\n",
    "            \n",
    "            return self._get_observation(), reward, done, {\n",
    "                'message': 'All pieces placed',\n",
    "                'waste': waste,\n",
    "                'efficiency': efficiency,\n",
    "                'platforms_used': len(self.platforms)\n",
    "            }\n",
    "        \n",
    "        return self._get_observation(), reward, done, {}\n",
    "    \n",
    "    def render(self):\n",
    "        # \"\"\"Render the current state of the environment.\"\"\"\n",
    "        \"\"\"Render the current state of the environment with different colors for each piece type.\"\"\"\n",
    "        piece_colors = ['white', 'red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'gray', 'pink', 'brown']\n",
    "\n",
    "        #################################################################################\n",
    "\n",
    "        fig, axs = plt.subplots(1, len(self.platforms), figsize=(5*len(self.platforms), 5))\n",
    "        if len(self.platforms) == 1:\n",
    "            axs = [axs]\n",
    "        \n",
    "        for i, platform in enumerate(self.platforms):\n",
    "            ax = axs[i]\n",
    "            \n",
    "            # Create a colored image\n",
    "            colored_image = np.zeros((self.grid_size, self.grid_size, 3))\n",
    "            \n",
    "            # Fill with colors based on piece types\n",
    "            for y in range(self.grid_size):\n",
    "                for x in range(self.grid_size):\n",
    "                    piece_type = self.piece_types[i][y, x]\n",
    "                    if piece_type > 0:\n",
    "                        # Convert color name to RGB\n",
    "                        color_name = piece_colors[piece_type]\n",
    "                        color_rgb = np.array(plt.matplotlib.colors.to_rgb(color_name))\n",
    "                        colored_image[y, x] = color_rgb\n",
    "            \n",
    "            ax.imshow(colored_image)\n",
    "            ax.set_title(f'Platform {i+1}')\n",
    "            ax.set_xlim(0, self.grid_size)\n",
    "            ax.set_ylim(0, self.grid_size)\n",
    "            ax.invert_yaxis()  # Invert y-axis to match grid coordinates\n",
    "            \n",
    "            # Draw grid lines\n",
    "            # Add grid lines (optional, for clarity)\n",
    "            ax.set_xticks(np.arange(-.5, self.grid_size, 10))\n",
    "            ax.set_yticks(np.arange(-.5, self.grid_size, 10))\n",
    "            ax.grid(True, color='black', linewidth=0.5, alpha=0.3)\n",
    "            \n",
    "            # Add piece outlines\n",
    "            for type_id in range(1, self.max_order_types + 1):\n",
    "                piece_mask = (self.piece_types[i] == type_id)\n",
    "                if not np.any(piece_mask):\n",
    "                    continue\n",
    "                    \n",
    "                # Find connected components\n",
    "                labeled, num_features = ndimage.label(piece_mask)\n",
    "                \n",
    "                for feature in range(1, num_features + 1):\n",
    "                    feature_mask = (labeled == feature)\n",
    "                    \n",
    "                    # Get the bounds of this feature\n",
    "                    ys, xs = np.where(feature_mask)\n",
    "                    x_min, x_max = np.min(xs), np.max(xs)\n",
    "                    y_min, y_max = np.min(ys), np.max(ys)\n",
    "                    \n",
    "                    # Draw rectangle around the piece\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x_min - 0.5, y_min - 0.5), \n",
    "                        x_max - x_min + 1, \n",
    "                        y_max - y_min + 1, \n",
    "                        linewidth=2, \n",
    "                        edgecolor='black', \n",
    "                        facecolor='none'\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "        \n",
    "        # Display remaining order with colors\n",
    "        order_text = []\n",
    "        for idx, (w, h, q) in enumerate(self.order):\n",
    "            if q > 0:\n",
    "                color = piece_colors[idx + 1]\n",
    "                order_text.append(f\"<span style='color:{color}'>{w}x{h} (qty: {q})</span>\")\n",
    "        \n",
    "        if order_text:\n",
    "            from matplotlib.text import Text\n",
    "            plt.figtext(0.5, 0.01, f\"Remaining pieces: {', '.join(order_text)}\", \n",
    "                    ha=\"center\", fontsize=9, bbox={\"facecolor\":\"white\", \"alpha\":0.8})\n",
    "        else:\n",
    "            plt.figtext(0.5, 0.01, \"All pieces placed!\", ha=\"center\", fontsize=9, \n",
    "                    bbox={\"facecolor\":\"green\", \"alpha\":0.5})\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(bottom=0.15)\n",
    "        plt.show()\n",
    "    def close(self):\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "\n",
    "class ActorCriticNetwork(nn.Module):\n",
    "    def __init__(self, input_shape, action_dims):\n",
    "        super(ActorCriticNetwork, self).__init__()\n",
    "        \n",
    "        # CNN for processing the grid\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        \n",
    "        # Calculate the size after convolutions\n",
    "        def conv2d_size_out(size, kernel_size=3, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "        conv_width = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[1], 5, 2)))\n",
    "        conv_height = conv2d_size_out(conv2d_size_out(conv2d_size_out(input_shape[0], 5, 2)))\n",
    "        linear_input_size = conv_width * conv_height * 64\n",
    "        \n",
    "        # FC for processing the order information\n",
    "        self.fc_order = nn.Linear(30, 128)  # 10 order types x 3 features (width, height, quantity)\n",
    "        \n",
    "        # FC for processing platform index\n",
    "        self.fc_platform = nn.Linear(1, 32)\n",
    "        \n",
    "        # Combine and process\n",
    "        self.fc_combine = nn.Linear(linear_input_size + 128 + 32, 512)\n",
    "        \n",
    "        # Actor head (policy)\n",
    "        self.actor_x = nn.Linear(512, action_dims[0])  # x position\n",
    "        self.actor_y = nn.Linear(512, action_dims[1])  # y position\n",
    "        self.actor_piece = nn.Linear(512, action_dims[2])  # piece type\n",
    "        self.actor_rotation = nn.Linear(512, action_dims[3])  # rotation\n",
    "        \n",
    "        # Critic head (value function)\n",
    "        self.critic = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, grid, order, platform_idx):\n",
    "        # Process grid\n",
    "        grid = grid.unsqueeze(1)  # Add channel dimension\n",
    "        grid = F.relu(self.conv1(grid))\n",
    "        grid = F.relu(self.conv2(grid))\n",
    "        grid = F.relu(self.conv3(grid))\n",
    "        grid = grid.view(grid.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Process order\n",
    "        order = order.view(order.size(0), -1)  # Flatten\n",
    "        order = F.relu(self.fc_order(order))\n",
    "        \n",
    "        # Process platform index\n",
    "        platform_idx = platform_idx.float().view(-1, 1)\n",
    "        platform = F.relu(self.fc_platform(platform_idx))\n",
    "        \n",
    "        # Combine\n",
    "        combined = torch.cat((grid, order, platform), dim=1)\n",
    "        features = F.relu(self.fc_combine(combined))\n",
    "        \n",
    "        # Actor outputs (policy distributions)\n",
    "        x_logits = self.actor_x(features)\n",
    "        y_logits = self.actor_y(features)\n",
    "        piece_logits = self.actor_piece(features)\n",
    "        rotation_logits = self.actor_rotation(features)\n",
    "        \n",
    "        # Critic output (value function)\n",
    "        value = self.critic(features)\n",
    "        \n",
    "        return x_logits, y_logits, piece_logits, rotation_logits, value\n",
    "\n",
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "    \n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "        \n",
    "        return batches\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_shape, action_space, device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                 lr=0.0003, gamma=0.99, gae_lambda=0.95, policy_clip=0.2, \n",
    "                 batch_size=64, n_epochs=10, entropy_coefficient=0.01):\n",
    "        self.state_shape = state_shape\n",
    "        self.action_space = action_space\n",
    "        self.device = device\n",
    "        \n",
    "        # PPO hyperparameters\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "        self.entropy_coefficient = entropy_coefficient\n",
    "        \n",
    "        # Create actor-critic network\n",
    "        self.actor_critic = ActorCriticNetwork(\n",
    "            input_shape=(state_shape['grid'][0], state_shape['grid'][1]),\n",
    "            action_dims=(action_space[0], action_space[1], action_space[2], action_space[3])\n",
    "        ).to(device)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.actor_critic.parameters(), lr=lr)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "        \n",
    "        # For handling actions\n",
    "        self.grid_size = state_shape['grid'][0]\n",
    "        self.max_order_types = state_shape['order'][0]\n",
    "        self.rotations = action_space[3]\n",
    "        \n",
    "    def choose_action(self, state, training=True):\n",
    "        # Convert state to tensors\n",
    "        grid = torch.FloatTensor(state['grid']).unsqueeze(0).to(self.device)\n",
    "        order = torch.FloatTensor(state['order']).unsqueeze(0).to(self.device)\n",
    "        platform_idx = torch.LongTensor([state['platform_index']]).to(self.device)\n",
    "        \n",
    "        # Get action distributions and value from actor-critic\n",
    "        with torch.no_grad():\n",
    "            x_logits, y_logits, piece_logits, rotation_logits, value = self.actor_critic(\n",
    "                grid, order, platform_idx\n",
    "            )\n",
    "        \n",
    "        # Create distributions for each action component\n",
    "        x_dist = Categorical(F.softmax(x_logits, dim=1))\n",
    "        y_dist = Categorical(F.softmax(y_logits, dim=1))\n",
    "        \n",
    "        # Mask invalid piece types (pieces with quantity 0)\n",
    "        piece_mask = torch.ones_like(piece_logits) * float('-inf')\n",
    "        for i, (_, _, qty) in enumerate(state['order']):\n",
    "            if qty > 0:\n",
    "                piece_mask[0, i] = 0  # Unmask valid piece types\n",
    "        \n",
    "        masked_piece_logits = piece_logits + piece_mask\n",
    "        piece_dist = Categorical(F.softmax(masked_piece_logits, dim=1))\n",
    "        rotation_dist = Categorical(F.softmax(rotation_logits, dim=1))\n",
    "        \n",
    "        # Sample actions from distributions (or take most likely action during evaluation)\n",
    "        if training:\n",
    "            x = x_dist.sample()\n",
    "            y = y_dist.sample()\n",
    "            piece_type = piece_dist.sample()\n",
    "            rotation = rotation_dist.sample()\n",
    "        else:\n",
    "            x = torch.argmax(x_dist.probs)\n",
    "            y = torch.argmax(y_dist.probs)\n",
    "            piece_type = torch.argmax(piece_dist.probs)\n",
    "            rotation = torch.argmax(rotation_dist.probs)\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        x_prob = x_dist.log_prob(x)\n",
    "        y_prob = y_dist.log_prob(y)\n",
    "        piece_prob = piece_dist.log_prob(piece_type)\n",
    "        rotation_prob = rotation_dist.log_prob(rotation)\n",
    "        \n",
    "        # Sum the log probs to get the total action log probability\n",
    "        action_log_prob = x_prob + y_prob + piece_prob + rotation_prob\n",
    "        \n",
    "        return [x.item(), y.item(), piece_type.item(), rotation.item()], action_log_prob.item(), value.item()\n",
    "    \n",
    "    def store_transition(self, state, action, action_log_prob, value, reward, done):\n",
    "        self.memory.store_memory(state, action, action_log_prob, value, reward, done)\n",
    "    \n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            # Calculate advantages and returns\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr, reward_arr, done_arr = self._process_memory()\n",
    "            \n",
    "            # Generate mini-batches\n",
    "            batches = self.memory.generate_batches()\n",
    "            \n",
    "            # Train on each batch\n",
    "            for batch in batches:\n",
    "                # Select batch components\n",
    "                grids = torch.FloatTensor(state_arr['grid'][batch]).to(self.device)\n",
    "                orders = torch.FloatTensor(state_arr['order'][batch]).to(self.device)\n",
    "                platform_idxs = torch.LongTensor(state_arr['platform_index'][batch]).to(self.device)\n",
    "                \n",
    "                actions = action_arr[batch]\n",
    "                old_probs = old_prob_arr[batch]\n",
    "                values = vals_arr[batch]\n",
    "                \n",
    "                # Calculate advantages and returns for the batch\n",
    "                advantages = self._calculate_advantages(\n",
    "                    reward_arr[batch], values, done_arr[batch]\n",
    "                )\n",
    "                returns = advantages + values\n",
    "                advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "                \n",
    "                # Forward pass\n",
    "                x_logits, y_logits, piece_logits, rotation_logits, critic_value = self.actor_critic(\n",
    "                    grids, orders, platform_idxs\n",
    "                )\n",
    "                \n",
    "                # Extract action components\n",
    "                x = actions[:, 0]\n",
    "                y = actions[:, 1]\n",
    "                piece_type = actions[:, 2]\n",
    "                rotation = actions[:, 3]\n",
    "                \n",
    "                # Create distributions\n",
    "                x_dist = Categorical(F.softmax(x_logits, dim=1))\n",
    "                y_dist = Categorical(F.softmax(y_logits, dim=1))\n",
    "                piece_dist = Categorical(F.softmax(piece_logits, dim=1))\n",
    "                rotation_dist = Categorical(F.softmax(rotation_logits, dim=1))\n",
    "                \n",
    "                # Calculate new log probabilities\n",
    "                x_new_probs = x_dist.log_prob(torch.LongTensor(x).to(self.device))\n",
    "                y_new_probs = y_dist.log_prob(torch.LongTensor(y).to(self.device))\n",
    "                piece_new_probs = piece_dist.log_prob(torch.LongTensor(piece_type).to(self.device))\n",
    "                rotation_new_probs = rotation_dist.log_prob(torch.LongTensor(rotation).to(self.device))\n",
    "                \n",
    "                # Combine log probabilities\n",
    "                new_probs = x_new_probs + y_new_probs + piece_new_probs + rotation_new_probs\n",
    "                \n",
    "                # Calculate probability ratio\n",
    "                prob_ratio = torch.exp(new_probs - torch.FloatTensor(old_probs).to(self.device))\n",
    "                \n",
    "                # Calculate surrogate losses\n",
    "                weighted_probs = advantages.to(self.device) * prob_ratio\n",
    "                weighted_clipped_probs = advantages.to(self.device) * torch.clamp(\n",
    "                    prob_ratio, 1-self.policy_clip, 1+self.policy_clip\n",
    "                )\n",
    "                actor_loss = -torch.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "                \n",
    "                # Add entropy bonus for exploration\n",
    "                entropy = x_dist.entropy().mean() + y_dist.entropy().mean() + \\\n",
    "                        piece_dist.entropy().mean() + rotation_dist.entropy().mean()\n",
    "                \n",
    "                # Calculate critic loss\n",
    "                returns = returns.float().to(self.device)  # Ensure returns is float32\n",
    "                critic_loss = F.mse_loss(critic_value.squeeze(), returns)\n",
    "                \n",
    "                # Calculate total loss\n",
    "                total_loss = actor_loss + 0.5 * critic_loss - self.entropy_coefficient * entropy\n",
    "                \n",
    "                # Update network\n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "        # Clear memory after learning\n",
    "        self.memory.clear_memory()\n",
    "\n",
    "    def _calculate_advantages(self, rewards, values, dones):\n",
    "        \"\"\"Calculate advantages using Generalized Advantage Estimation (GAE).\"\"\"\n",
    "        advantages = np.zeros_like(rewards)\n",
    "        gae = 0\n",
    "        \n",
    "        for t in reversed(range(len(rewards))):\n",
    "            if t == len(rewards) - 1:\n",
    "                next_value = 0\n",
    "            else:\n",
    "                next_value = values[t + 1]\n",
    "            \n",
    "            delta = rewards[t] + self.gamma * next_value * (1 - dones[t]) - values[t]\n",
    "            gae = delta + self.gamma * self.gae_lambda * (1 - dones[t]) * gae\n",
    "            advantages[t] = gae\n",
    "        \n",
    "        return torch.tensor(advantages, dtype=torch.float32)  # Explicitly use float32\n",
    "    \n",
    "    def _process_memory(self):\n",
    "        \"\"\"Process memory data into arrays.\"\"\"\n",
    "        # States need special handling due to being dictionaries\n",
    "        state_arr = {\n",
    "            'grid': [],\n",
    "            'order': [],\n",
    "            'platform_index': []\n",
    "        }\n",
    "        \n",
    "        for state in self.memory.states:\n",
    "            state_arr['grid'].append(state['grid'])\n",
    "            state_arr['order'].append(state['order'])\n",
    "            state_arr['platform_index'].append(state['platform_index'])\n",
    "        \n",
    "        # Convert states to numpy arrays\n",
    "        state_arr = {k: np.array(v) for k, v in state_arr.items()}\n",
    "        \n",
    "        # Convert other memory components to numpy arrays\n",
    "        action_arr = np.array(self.memory.actions)\n",
    "        old_prob_arr = np.array(self.memory.probs)\n",
    "        vals_arr = np.array(self.memory.vals)\n",
    "        reward_arr = np.array(self.memory.rewards)\n",
    "        done_arr = np.array(self.memory.dones)\n",
    "        \n",
    "        return state_arr, action_arr, old_prob_arr, vals_arr, reward_arr, done_arr\n",
    "    \n",
    "    def _calculate_advantages(self, rewards, values, dones):\n",
    "        \"\"\"Calculate advantages using Generalized Advantage Estimation (GAE).\"\"\"\n",
    "        advantages = np.zeros_like(rewards)\n",
    "        gae = 0\n",
    "        \n",
    "        for t in reversed(range(len(rewards))):\n",
    "            if t == len(rewards) - 1:\n",
    "                next_value = 0\n",
    "            else:\n",
    "                next_value = values[t + 1]\n",
    "            \n",
    "            delta = rewards[t] + self.gamma * next_value * (1 - dones[t]) - values[t]\n",
    "            gae = delta + self.gamma * self.gae_lambda * (1 - dones[t]) * gae\n",
    "            advantages[t] = gae\n",
    "        \n",
    "        return torch.FloatTensor(advantages)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save({\n",
    "            'actor_critic': self.actor_critic.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        checkpoint = torch.load(path, map_location=self.device)\n",
    "        self.actor_critic.load_state_dict(checkpoint['actor_critic'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_order_example():\n",
    "    \"\"\"Example of using a custom order with PPO agent.\"\"\"\n",
    "    # Create environment\n",
    "    env = WoodCuttingEnv()\n",
    "    \n",
    "    # Create and load agent\n",
    "    agent = PPOAgent(\n",
    "        state_shape={\n",
    "            'grid': env.observation_space['grid'].shape,\n",
    "            'order': env.observation_space['order'].shape,\n",
    "            'platform_index': (1,)\n",
    "        },\n",
    "        action_space=env.action_space.nvec\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        agent.load_model('models/ppo_wood_cutting_final.pth')\n",
    "        print(\"Loaded trained model\")\n",
    "    except:\n",
    "        print(\"No trained model found, using untrained agent\")\n",
    "    \n",
    "    # Define a custom order\n",
    "    # Format: [[width, height, quantity], ...]\n",
    "    # custom_order = np.array([\n",
    "    #     [30, 20, 5],   # 5 pieces of 30x20\n",
    "    #     [25, 15, 8],   # 8 pieces of 25x15\n",
    "    #     [40, 10, 3],   # 3 pieces of 40x10\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0],     # Padding\n",
    "    #     [0, 0, 0]      # Padding\n",
    "    # ])\n",
    "    custom_order = np.array([\n",
    "        [40, 40, 1],   # red\n",
    "        [60, 60, 2],   # blue\n",
    "        [40, 30, 10],   # green\n",
    "        [20, 10, 9],     # black\n",
    "        [0, 0, 0],     # orange\n",
    "        [0, 0, 0],     # yellow\n",
    "        [0, 0, 0],     # purple\n",
    "        [0, 0, 0],     # gray\n",
    "        [0, 0, 0],     # pink\n",
    "        [0, 0, 0]      # brown\n",
    "    ])\n",
    "    \n",
    "    # Reset environment with custom order\n",
    "    state = env.reset(order=custom_order)\n",
    "    \n",
    "    # Run episode with custom order\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    max_steps = 200\n",
    "    \n",
    "    print(\"Starting custom order optimization with PPO...\")\n",
    "    \n",
    "    while not done and steps < max_steps:\n",
    "        # Choose action\n",
    "        action, _, _ = agent.choose_action(state, training=False)\n",
    "        \n",
    "        # Take action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Update state and total reward\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Order completed in {steps} steps\")\n",
    "            print(f\"Total reward: {total_reward:.2f}\")\n",
    "            if 'waste' in info:\n",
    "                print(f\"Waste: {info['waste']}\")\n",
    "                print(f\"Efficiency: {info['efficiency']:.2f}\")\n",
    "                print(f\"Platforms used: {info['platforms_used']}\")\n",
    "    \n",
    "    # Render final state\n",
    "    env.render()\n",
    "    \n",
    "    if not done:\n",
    "        print(f\"Failed to complete order within {max_steps} steps\")\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model\n",
      "Starting custom order optimization with PPO...\n",
      "Order completed in 22 steps\n",
      "Total reward: 22925.00\n",
      "Waste: 17400\n",
      "Efficiency: 0.56\n",
      "Platforms used: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(22925.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_order_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
